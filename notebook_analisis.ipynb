{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸŽ“ PrÃ¡ctica de Machine Learning: PredicciÃ³n de Rendimiento AcadÃ©mico\n",
    "\n",
    "**Estudiante:** [Tu Nombre]\n",
    "\n",
    "**Fecha:** Diciembre 2024\n",
    "\n",
    "## Objetivos\n",
    "\n",
    "1. Implementar un modelo supervisado de clasificaciÃ³n para predecir aprobaciÃ³n/reprobaciÃ³n\n",
    "2. Aplicar clustering (K-means) para identificar grupos de estudiantes\n",
    "3. Comparar y evaluar ambos modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ImportaciÃ³n de LibrerÃ­as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LibrerÃ­as bÃ¡sicas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ConfiguraciÃ³n de visualizaciÃ³n\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "print(\"âœ… LibrerÃ­as importadas correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Carga y ExploraciÃ³n de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar dataset\n",
    "df = pd.read_csv('data/academic_performance_master.csv')\n",
    "\n",
    "print(f\"ðŸ“Š Dimensiones del dataset: {df.shape}\")\n",
    "print(f\"ðŸ“‹ Columnas: {df.shape[1]}\")\n",
    "print(f\"ðŸ‘¥ Registros: {df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vista previa\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# InformaciÃ³n del dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EstadÃ­sticas descriptivas\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 AnÃ¡lisis de Calidad de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valores nulos\n",
    "print(\"ðŸ” Valores Nulos por Columna:\")\n",
    "nulos = df.isnull().sum()\n",
    "print(nulos[nulos > 0])\n",
    "\n",
    "if nulos.sum() == 0:\n",
    "    print(\"\\nâœ… No se encontraron valores nulos\")\n",
    "else:\n",
    "    print(f\"\\nâš ï¸ Total de valores nulos: {nulos.sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valores duplicados\n",
    "duplicados = df.duplicated().sum()\n",
    "print(f\"Filas duplicadas: {duplicados}\")\n",
    "\n",
    "if duplicados == 0:\n",
    "    print(\"âœ… No se encontraron duplicados\")\n",
    "else:\n",
    "    print(f\"âš ï¸ Se encontraron {duplicados} filas duplicadas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 VisualizaciÃ³n de la DistribuciÃ³n de Notas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DistribuciÃ³n de notas finales\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Histograma\n",
    "axes[0].hist(df['Nota_final'].dropna(), bins=25, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "axes[0].axvline(df['Nota_final'].mean(), color='red', linestyle='--', linewidth=2, label=f'Media: {df[\"Nota_final\"].mean():.2f}')\n",
    "axes[0].axvline(df['Nota_final'].median(), color='green', linestyle='--', linewidth=2, label=f'Mediana: {df[\"Nota_final\"].median():.2f}')\n",
    "axes[0].set_title('DistribuciÃ³n de Notas Finales', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Nota Final')\n",
    "axes[0].set_ylabel('Frecuencia')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Boxplot\n",
    "axes[1].boxplot(df['Nota_final'].dropna())\n",
    "axes[1].set_title('Boxplot de Notas Finales', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('Nota Final')\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# EstadÃ­sticas\n",
    "print(f\"ðŸ“Š EstadÃ­sticas de Nota Final:\")\n",
    "print(f\"  - MÃ­nimo: {df['Nota_final'].min():.2f}\")\n",
    "print(f\"  - MÃ¡ximo: {df['Nota_final'].max():.2f}\")\n",
    "print(f\"  - Media: {df['Nota_final'].mean():.2f}\")\n",
    "print(f\"  - Mediana: {df['Nota_final'].median():.2f}\")\n",
    "print(f\"  - Desv. EstÃ¡ndar: {df['Nota_final'].std():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. PreparaciÃ³n de Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 DefiniciÃ³n del Umbral de AprobaciÃ³n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular umbral sugerido (percentil 40)\n",
    "umbral_sugerido = df['Nota_final'].quantile(0.4)\n",
    "print(f\"ðŸ“Š Umbral sugerido (percentil 40): {umbral_sugerido:.2f}\")\n",
    "\n",
    "# Puedes ajustar este valor\n",
    "UMBRAL_APROBACION = 14.0  # Ajusta segÃºn tu anÃ¡lisis\n",
    "\n",
    "print(f\"\\nâœ… Umbral seleccionado: {UMBRAL_APROBACION}\")\n",
    "\n",
    "# Verificar distribuciÃ³n\n",
    "aprobados = (df['Nota_final'] >= UMBRAL_APROBACION).sum()\n",
    "reprobados = (df['Nota_final'] < UMBRAL_APROBACION).sum()\n",
    "total = len(df['Nota_final'].dropna())\n",
    "\n",
    "print(f\"\\nðŸ“Š DistribuciÃ³n con umbral {UMBRAL_APROBACION}:\")\n",
    "print(f\"  âœ… Aprobados: {aprobados} ({aprobados/total*100:.1f}%)\")\n",
    "print(f\"  âŒ Reprobados: {reprobados} ({reprobados/total*100:.1f}%)\")\n",
    "\n",
    "if aprobados == 0 or reprobados == 0:\n",
    "    print(\"\\nâš ï¸ ADVERTENCIA: Solo hay una clase. Ajusta el UMBRAL_APROBACION\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 SelecciÃ³n y PreparaciÃ³n de Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar columnas relevantes\n",
    "# Variables numÃ©ricas\n",
    "variables_numericas = ['Asistencia']  # Ajusta segÃºn tus datos\n",
    "\n",
    "# Variables categÃ³ricas\n",
    "variables_categoricas = ['Nivel', 'Carrera', 'Tipo_Ingreso']  # Ajusta segÃºn tus datos\n",
    "\n",
    "# Crear dataset\n",
    "columnas_usar = ['Nota_final'] + variables_numericas + variables_categoricas\n",
    "df_prep = df[columnas_usar].copy()\n",
    "\n",
    "print(f\"ðŸ“‹ Variables seleccionadas: {len(columnas_usar)}\")\n",
    "print(f\"  - NumÃ©ricas: {variables_numericas}\")\n",
    "print(f\"  - CategÃ³ricas: {variables_categoricas}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpiar valores nulos\n",
    "nulos_antes = df_prep.isnull().sum().sum()\n",
    "df_prep = df_prep.dropna()\n",
    "nulos_despues = df_prep.isnull().sum().sum()\n",
    "\n",
    "print(f\"ðŸ§¹ Limpieza de datos:\")\n",
    "print(f\"  - Nulos eliminados: {nulos_antes}\")\n",
    "print(f\"  - Registros finales: {len(df_prep)}\")\n",
    "print(f\"  - Nulos restantes: {nulos_despues}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codificar variables categÃ³ricas\n",
    "le = LabelEncoder()\n",
    "\n",
    "for col in variables_categoricas:\n",
    "    if col in df_prep.columns:\n",
    "        df_prep[col] = le.fit_transform(df_prep[col].astype(str))\n",
    "        print(f\"âœ… '{col}' codificada\")\n",
    "\n",
    "print(\"\\nâœ… Todas las variables categÃ³ricas han sido codificadas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear variable objetivo\n",
    "df_prep['Aprobado'] = (df_prep['Nota_final'] >= UMBRAL_APROBACION).astype(int)\n",
    "\n",
    "# Verificar balance\n",
    "distribucion = df_prep['Aprobado'].value_counts()\n",
    "print(\"ðŸ“Š DistribuciÃ³n de clases:\")\n",
    "print(distribucion)\n",
    "print(f\"\\nâœ… Balance: {min(distribucion)/max(distribucion):.2%}\")\n",
    "\n",
    "# Mostrar muestra\n",
    "df_prep.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Modelo Supervisado: ClasificaciÃ³n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 PreparaciÃ³n de Datos para Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar caracterÃ­sticas (X) y objetivo (y)\n",
    "X = df_prep[variables_numericas + variables_categoricas]\n",
    "y = df_prep['Aprobado']\n",
    "\n",
    "print(f\"ðŸ“Š Dimensiones:\")\n",
    "print(f\"  - X (caracterÃ­sticas): {X.shape}\")\n",
    "print(f\"  - y (objetivo): {y.shape}\")\n",
    "print(f\"\\nðŸ“‹ Variables predictoras: {list(X.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DivisiÃ³n train/test\n",
    "TEST_SIZE = 0.2\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=TEST_SIZE, \n",
    "    random_state=RANDOM_STATE, \n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(f\"ðŸ“Š DivisiÃ³n de datos (test_size={TEST_SIZE}):\")\n",
    "print(f\"  - Entrenamiento: {len(X_train)} muestras\")\n",
    "print(f\"  - Prueba: {len(X_test)} muestras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escalado de caracterÃ­sticas\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"âœ… CaracterÃ­sticas escaladas con StandardScaler\")\n",
    "print(f\"   Media: ~0, Desv. EstÃ¡ndar: ~1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Entrenamiento del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo 1: RegresiÃ³n LogÃ­stica\n",
    "print(\"ðŸ¤– Entrenando RegresiÃ³n LogÃ­stica...\")\n",
    "\n",
    "modelo_lr = LogisticRegression(random_state=RANDOM_STATE, max_iter=1000)\n",
    "modelo_lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predicciones\n",
    "y_pred_lr = modelo_lr.predict(X_test_scaled)\n",
    "y_pred_proba_lr = modelo_lr.predict_proba(X_test_scaled)\n",
    "\n",
    "# Accuracy\n",
    "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "\n",
    "print(f\"\\nâœ… Modelo entrenado\")\n",
    "print(f\"ðŸŽ¯ Accuracy: {accuracy_lr:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo 2: Ãrbol de DecisiÃ³n\n",
    "print(\"ðŸŒ³ Entrenando Ãrbol de DecisiÃ³n...\")\n",
    "\n",
    "modelo_dt = DecisionTreeClassifier(random_state=RANDOM_STATE)\n",
    "modelo_dt.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_dt = modelo_dt.predict(X_test_scaled)\n",
    "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
    "\n",
    "print(f\"âœ… Modelo entrenado\")\n",
    "print(f\"ðŸŽ¯ Accuracy: {accuracy_dt:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo 3: Random Forest\n",
    "print(\"ðŸŒ² Entrenando Random Forest...\")\n",
    "\n",
    "modelo_rf = RandomForestClassifier(random_state=RANDOM_STATE, n_estimators=100)\n",
    "modelo_rf.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_rf = modelo_rf.predict(X_test_scaled)\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "\n",
    "print(f\"âœ… Modelo entrenado\")\n",
    "print(f\"ðŸŽ¯ Accuracy: {accuracy_rf:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 EvaluaciÃ³n de Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ComparaciÃ³n de accuracies\n",
    "resultados = pd.DataFrame({\n",
    "    'Modelo': ['RegresiÃ³n LogÃ­stica', 'Ãrbol de DecisiÃ³n', 'Random Forest'],\n",
    "    'Accuracy': [accuracy_lr, accuracy_dt, accuracy_rf]\n",
    "}).sort_values('Accuracy', ascending=False)\n",
    "\n",
    "print(\"ðŸ“Š ComparaciÃ³n de Modelos:\")\n",
    "print(resultados.to_string(index=False))\n",
    "\n",
    "mejor_modelo = resultados.iloc[0]['Modelo']\n",
    "mejor_accuracy = resultados.iloc[0]['Accuracy']\n",
    "print(f\"\\nðŸ† Mejor modelo: {mejor_modelo} ({mejor_accuracy:.2%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VisualizaciÃ³n de comparaciÃ³n\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "colors = ['#2ecc71' if acc >= 0.9 else '#3498db' if acc >= 0.8 else '#e74c3c' \n",
    "          for acc in resultados['Accuracy']]\n",
    "\n",
    "bars = ax.barh(resultados['Modelo'], resultados['Accuracy'], color=colors, alpha=0.7, edgecolor='black')\n",
    "\n",
    "# AÃ±adir valores en las barras\n",
    "for i, (bar, acc) in enumerate(zip(bars, resultados['Accuracy'])):\n",
    "    ax.text(acc + 0.01, i, f'{acc:.2%}', va='center', fontweight='bold', fontsize=11)\n",
    "\n",
    "ax.set_xlabel('Accuracy', fontsize=12, fontweight='bold')\n",
    "ax.set_title('ComparaciÃ³n de Modelos de ClasificaciÃ³n', fontsize=14, fontweight='bold')\n",
    "ax.set_xlim(0, 1.1)\n",
    "ax.grid(axis='x', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Matriz de ConfusiÃ³n (Mejor Modelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usar el mejor modelo (RegresiÃ³n LogÃ­stica para este ejemplo)\n",
    "y_pred_mejor = y_pred_lr\n",
    "\n",
    "# Matriz de confusiÃ³n\n",
    "cm = confusion_matrix(y_test, y_pred_mejor)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "           xticklabels=['Reprobado (0)', 'Aprobado (1)'],\n",
    "           yticklabels=['Reprobado (0)', 'Aprobado (1)'],\n",
    "           cbar_kws={'label': 'Frecuencia'},\n",
    "           annot_kws={'size': 16, 'weight': 'bold'})\n",
    "\n",
    "ax.set_title('Matriz de ConfusiÃ³n - RegresiÃ³n LogÃ­stica', fontsize=14, fontweight='bold')\n",
    "ax.set_ylabel('Valor Real', fontsize=12)\n",
    "ax.set_xlabel('PredicciÃ³n', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ“Š InterpretaciÃ³n:\")\n",
    "print(f\"  - Verdaderos Negativos (TN): {cm[0,0]} - Reprobados correctamente predichos\")\n",
    "print(f\"  - Falsos Positivos (FP): {cm[0,1]} - Reprobados predichos como aprobados\")\n",
    "print(f\"  - Falsos Negativos (FN): {cm[1,0]} - Aprobados predichos como reprobados\")\n",
    "print(f\"  - Verdaderos Positivos (TP): {cm[1,1]} - Aprobados correctamente predichos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Reporte de ClasificaciÃ³n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reporte detallado\n",
    "print(\"ðŸ“‹ Reporte de ClasificaciÃ³n:\")\n",
    "print(\"=\"*60)\n",
    "print(classification_report(y_test, y_pred_mejor, \n",
    "                          target_names=['Reprobado', 'Aprobado']))\n",
    "\n",
    "# Como DataFrame\n",
    "report_dict = classification_report(y_test, y_pred_mejor, \n",
    "                                   target_names=['Reprobado', 'Aprobado'],\n",
    "                                   output_dict=True)\n",
    "report_df = pd.DataFrame(report_dict).transpose()\n",
    "report_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 Importancia de Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importancia de caracterÃ­sticas (RegresiÃ³n LogÃ­stica)\n",
    "importancias = pd.DataFrame({\n",
    "    'Variable': X.columns,\n",
    "    'Coeficiente': modelo_lr.coef_[0],\n",
    "    'Importancia_Abs': np.abs(modelo_lr.coef_[0])\n",
    "}).sort_values('Importancia_Abs', ascending=False)\n",
    "\n",
    "print(\"ðŸ“Š Importancia de Variables:\")\n",
    "print(importancias[['Variable', 'Coeficiente']])\n",
    "\n",
    "# VisualizaciÃ³n\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "colors = ['green' if x > 0 else 'red' for x in importancias['Coeficiente']]\n",
    "ax.barh(importancias['Variable'], importancias['Coeficiente'], color=colors, alpha=0.7, edgecolor='black')\n",
    "ax.set_xlabel('Coeficiente', fontsize=12)\n",
    "ax.set_title('Importancia de Variables\\n(Verde: Influencia Positiva | Rojo: Influencia Negativa)', \n",
    "            fontsize=14, fontweight='bold')\n",
    "ax.axvline(x=0, color='black', linestyle='--', linewidth=1)\n",
    "ax.grid(axis='x', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Modelo No Supervisado: Clustering (K-means)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 PreparaciÃ³n de Datos para Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar variables para clustering\n",
    "VAR_X = 'Asistencia'\n",
    "VAR_Y = 'Nota_final'\n",
    "\n",
    "df_cluster = df[[VAR_X, VAR_Y]].dropna()\n",
    "\n",
    "print(f\"ðŸ“Š Variables para clustering:\")\n",
    "print(f\"  - X: {VAR_X}\")\n",
    "print(f\"  - Y: {VAR_Y}\")\n",
    "print(f\"  - Registros: {len(df_cluster)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escalado\n",
    "scaler_cluster = StandardScaler()\n",
    "X_cluster_scaled = scaler_cluster.fit_transform(df_cluster)\n",
    "\n",
    "print(\"âœ… Datos escalados para clustering\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 AplicaciÃ³n de K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-means con 3 clusters\n",
    "N_CLUSTERS = 3\n",
    "\n",
    "print(f\"ðŸ” Aplicando K-means con {N_CLUSTERS} clusters...\")\n",
    "\n",
    "kmeans = KMeans(n_clusters=N_CLUSTERS, random_state=42, n_init=10)\n",
    "clusters = kmeans.fit_predict(X_cluster_scaled)\n",
    "\n",
    "df_cluster['Cluster'] = clusters\n",
    "\n",
    "print(f\"âœ… Clustering completado\")\n",
    "print(f\"\\nðŸ“Š DistribuciÃ³n de clusters:\")\n",
    "print(df_cluster['Cluster'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 VisualizaciÃ³n de Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VisualizaciÃ³n principal\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "scatter = ax.scatter(df_cluster[VAR_X], df_cluster[VAR_Y], \n",
    "                     c=clusters, cmap='viridis', alpha=0.6, s=100, \n",
    "                     edgecolors='black', linewidth=0.5)\n",
    "\n",
    "# Centroides\n",
    "centroides = scaler_cluster.inverse_transform(kmeans.cluster_centers_)\n",
    "ax.scatter(centroides[:, 0], centroides[:, 1], \n",
    "          c='red', marker='X', s=500, edgecolors='black',\n",
    "          linewidths=3, label='Centroides', zorder=5)\n",
    "\n",
    "# Etiquetar centroides\n",
    "for i, (x, y) in enumerate(centroides):\n",
    "    ax.annotate(f'C{i}', (x, y), fontsize=14, fontweight='bold', \n",
    "               color='white', ha='center', va='center')\n",
    "\n",
    "ax.set_xlabel(VAR_X, fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel(VAR_Y, fontsize=12, fontweight='bold')\n",
    "ax.set_title(f'Clustering K-means (k={N_CLUSTERS})', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "cbar = plt.colorbar(scatter, ax=ax)\n",
    "cbar.set_label('Cluster', fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 AnÃ¡lisis de Cada Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EstadÃ­sticas por cluster\n",
    "print(\"ðŸ“Š AnÃ¡lisis Detallado por Cluster:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for i in range(N_CLUSTERS):\n",
    "    cluster_data = df_cluster[df_cluster['Cluster'] == i]\n",
    "    n_estudiantes = len(cluster_data)\n",
    "    \n",
    "    print(f\"\\nðŸ”¹ Cluster {i} - {n_estudiantes} estudiantes\")\n",
    "    print(f\"  {VAR_X}:\")\n",
    "    print(f\"    - Promedio: {cluster_data[VAR_X].mean():.2f}\")\n",
    "    print(f\"    - Desv. Est: {cluster_data[VAR_X].std():.2f}\")\n",
    "    print(f\"    - Min: {cluster_data[VAR_X].min():.2f}\")\n",
    "    print(f\"    - Max: {cluster_data[VAR_X].max():.2f}\")\n",
    "    \n",
    "    print(f\"  {VAR_Y}:\")\n",
    "    print(f\"    - Promedio: {cluster_data[VAR_Y].mean():.2f}\")\n",
    "    print(f\"    - Desv. Est: {cluster_data[VAR_Y].std():.2f}\")\n",
    "    print(f\"    - Min: {cluster_data[VAR_Y].min():.2f}\")\n",
    "    print(f\"    - Max: {cluster_data[VAR_Y].max():.2f}\")\n",
    "    \n",
    "    # InterpretaciÃ³n\n",
    "    if cluster_data[VAR_Y].mean() > df_cluster[VAR_Y].mean():\n",
    "        if cluster_data[VAR_X].mean() > df_cluster[VAR_X].mean():\n",
    "            perfil = \"âœ… Alto rendimiento con buena asistencia\"\n",
    "        else:\n",
    "            perfil = \"ðŸ“Š Buen rendimiento pero asistencia mejorable\"\n",
    "    else:\n",
    "        if cluster_data[VAR_X].mean() < df_cluster[VAR_X].mean():\n",
    "            perfil = \"âš ï¸ Bajo rendimiento y baja asistencia (REQUIERE ATENCIÃ“N)\"\n",
    "        else:\n",
    "            perfil = \"ðŸ“‰ Asistencia aceptable pero bajo rendimiento\"\n",
    "    \n",
    "    print(f\"  ðŸ“‹ Perfil: {perfil}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumen estadÃ­stico como DataFrame\n",
    "resumen_clusters = df_cluster.groupby('Cluster')[[VAR_X, VAR_Y]].agg(['mean', 'std', 'min', 'max'])\n",
    "print(\"\\nðŸ“Š Resumen EstadÃ­stico por Cluster:\")\n",
    "resumen_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 MÃ©todo del Codo (Elbow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar diferentes valores de k\n",
    "inertias = []\n",
    "K_range = range(2, 8)\n",
    "\n",
    "for k in K_range:\n",
    "    km_temp = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    km_temp.fit(X_cluster_scaled)\n",
    "    inertias.append(km_temp.inertia_)\n",
    "\n",
    "# VisualizaciÃ³n\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.plot(K_range, inertias, 'bo-', linewidth=2, markersize=8)\n",
    "ax.axvline(x=N_CLUSTERS, color='red', linestyle='--', linewidth=2, \n",
    "          label=f'k seleccionado = {N_CLUSTERS}')\n",
    "ax.set_xlabel('NÃºmero de Clusters (k)', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Inercia', fontsize=12, fontweight='bold')\n",
    "ax.set_title('MÃ©todo del Codo para K-means', fontsize=14, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ComparaciÃ³n de Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Resumen de Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"ðŸ“Š RESUMEN DE MODELOS IMPLEMENTADOS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nðŸ¤– MODELO SUPERVISADO: CLASIFICACIÃ“N\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"  Algoritmo: RegresiÃ³n LogÃ­stica\")\n",
    "print(f\"  Accuracy: {accuracy_lr:.2%}\")\n",
    "print(f\"  Objetivo: Predecir Aprobado/Reprobado\")\n",
    "print(f\"  Variables: {', '.join(X.columns)}\")\n",
    "\n",
    "print(\"\\nðŸ” MODELO NO SUPERVISADO: CLUSTERING\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"  Algoritmo: K-means\")\n",
    "print(f\"  NÃºmero de clusters: {N_CLUSTERS}\")\n",
    "print(f\"  Objetivo: Agrupar estudiantes por patrones\")\n",
    "print(f\"  Variables: {VAR_X}, {VAR_Y}\")\n",
    "print(f\"  DistribuciÃ³n: {df_cluster['Cluster'].value_counts().to_dict()}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Â¿QuÃ© Modelo es Mejor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\\nðŸ’¡ COMPARACIÃ“N Y CONCLUSIONES\n",
    "=\"*70\n",
    "\n",
    "â“ Â¿QuÃ© modelo es mejor?\n",
    "\n",
    "No hay un modelo \"mejor\" en tÃ©rminos absolutos. Cada uno sirve para \n",
    "propÃ³sitos DIFERENTES:\n",
    "\n",
    "ðŸ¤– MODELO SUPERVISADO (ClasificaciÃ³n):\n",
    "  âœ… Ventajas:\n",
    "    - Predice resultados especÃ­ficos (Aprobado/Reprobado)\n",
    "    - Permite medir accuracy y otras mÃ©tricas cuantitativas\n",
    "    - Ãštil para predicciones futuras de nuevos estudiantes\n",
    "    - Identifica quÃ© variables influyen mÃ¡s en el resultado\n",
    "  \n",
    "  âŒ Limitaciones:\n",
    "    - Requiere datos etiquetados (conocer el resultado)\n",
    "    - Depende de la calidad del umbral definido\n",
    "    - Puede no capturar patrones complejos no lineales\n",
    "\n",
    "ðŸ” MODELO NO SUPERVISADO (Clustering):\n",
    "  âœ… Ventajas:\n",
    "    - Descubre patrones ocultos sin etiquetas previas\n",
    "    - Identifica grupos naturales de estudiantes\n",
    "    - Ãštil para segmentaciÃ³n y perfiles\n",
    "    - No requiere conocer el resultado de antemano\n",
    "  \n",
    "  âŒ Limitaciones:\n",
    "    - No predice valores especÃ­ficos\n",
    "    - InterpretaciÃ³n mÃ¡s subjetiva\n",
    "    - No tiene mÃ©tricas de precisiÃ³n directas\n",
    "    - Requiere definir nÃºmero de clusters manualmente\n",
    "\n",
    "ðŸ”„ RECOMENDACIÃ“N: USO COMPLEMENTARIO\n",
    "\n",
    "La mejor estrategia es usar AMBOS modelos:\n",
    "\n",
    "1. Clustering â†’ Identifica grupos de riesgo o perfiles\n",
    "2. ClasificaciÃ³n â†’ Predice resultados individuales\n",
    "3. IntervenciÃ³n â†’ Acciones personalizadas segÃºn cluster + predicciÃ³n\n",
    "\n",
    "ðŸ“Š EJEMPLO PRÃCTICO:\n",
    "  - Clustering detecta: \"Grupo de estudiantes con baja asistencia\"\n",
    "  - ClasificaciÃ³n predice: \"Juan tiene 85% probabilidad de reprobar\"\n",
    "  - AcciÃ³n: TutorÃ­as focalizadas para Juan y su grupo\n",
    "\n",
    "=\"*70\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Conclusiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\\nðŸ“ CONCLUSIONES DE LA PRÃCTICA\n",
    "=\"*70\n",
    "\n",
    "âœ… LOGROS OBTENIDOS:\n",
    "\n",
    "1. Dataset preparado exitosamente:\n",
    "   - {} registros limpios\n",
    "   - {} variables predictoras\n",
    "   - Balance de clases: {:.1%}\n",
    "\n",
    "2. Modelo Supervisado implementado:\n",
    "   - Accuracy alcanzado: {:.2%}\n",
    "   - DesempeÃ±o: {}\n",
    "   - Variables mÃ¡s influyentes identificadas\n",
    "\n",
    "3. Clustering aplicado:\n",
    "   - {} grupos de estudiantes identificados\n",
    "   - Perfiles claramente diferenciados\n",
    "   - Grupos de riesgo detectados\n",
    "\n",
    "ðŸ“Š HALLAZGOS PRINCIPALES:\n",
    "\n",
    "- La {} es la variable mÃ¡s importante para predecir aprobaciÃ³n\n",
    "- Se identificaron {} perfiles distintos de estudiantes\n",
    "- Los estudiantes con {} requieren atenciÃ³n especial\n",
    "\n",
    "ðŸ’¡ APLICACIONES PRÃCTICAS:\n",
    "\n",
    "1. Sistema de alerta temprana de reprobaciÃ³n\n",
    "2. SegmentaciÃ³n para tutorÃ­as personalizadas\n",
    "3. IdentificaciÃ³n de factores de riesgo acadÃ©mico\n",
    "4. OptimizaciÃ³n de recursos educativos\n",
    "\n",
    "ðŸŽ“ APRENDIZAJES:\n",
    "\n",
    "- ImplementaciÃ³n de modelos supervisados y no supervisados\n",
    "- EvaluaciÃ³n de modelos con mÃ©tricas apropiadas\n",
    "- InterpretaciÃ³n de resultados para toma de decisiones\n",
    "- Uso complementario de diferentes tÃ©cnicas de ML\n",
    "\n",
    "=\"*70\n",
    "\"\"\".format(\n",
    "    len(df_prep),\n",
    "    len(X.columns),\n",
    "    min(distribucion)/max(distribucion),\n",
    "    accuracy_lr,\n",
    "    'Excelente' if accuracy_lr >= 0.9 else 'Bueno' if accuracy_lr >= 0.8 else 'Aceptable',\n",
    "    N_CLUSTERS,\n",
    "    importancias.iloc[0]['Variable'],\n",
    "    N_CLUSTERS,\n",
    "    \"baja asistencia y bajo rendimiento\"\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Exportar Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar resultados en CSV\n",
    "# Predicciones del modelo supervisado\n",
    "resultados_pred = pd.DataFrame({\n",
    "    'y_real': y_test,\n",
    "    'y_pred': y_pred_mejor,\n",
    "    'prob_reprobado': y_pred_proba_lr[:, 0],\n",
    "    'prob_aprobado': y_pred_proba_lr[:, 1]\n",
    "})\n",
    "resultados_pred.to_csv('resultados_predicciones.csv', index=False)\n",
    "print(\"âœ… Predicciones guardadas en 'resultados_predicciones.csv'\")\n",
    "\n",
    "# Resultados del clustering\n",
    "df_cluster.to_csv('resultados_clustering.csv', index=False)\n",
    "print(\"âœ… Clustering guardado en 'resultados_clustering.csv'\")\n",
    "\n",
    "print(\"\\nðŸŽ‰ Â¡PrÃ¡ctica completada exitosamente!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}