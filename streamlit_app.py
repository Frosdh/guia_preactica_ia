import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.cluster import KMeans
import warnings
warnings.filterwarnings('ignore')

# Configuraci√≥n de la p√°gina
st.set_page_config(page_title="Pr√°ctica IA - Predicci√≥n Acad√©mica", layout="wide", page_icon="üéì")

# T√≠tulo principal
st.title("üéì Sistema de Predicci√≥n de Rendimiento Acad√©mico")
st.markdown("### Modelos de Machine Learning: Supervisado y No Supervisado")
st.markdown("---")

# Sidebar para navegaci√≥n
st.sidebar.title("üìä Navegaci√≥n")
st.sidebar.markdown("Selecciona la secci√≥n que deseas explorar:")
opcion = st.sidebar.radio(
    "",
    ["üè† Inicio", "üìÇ Exploraci√≥n de Datos", "üßπ Preparaci√≥n de Datos", "ü§ñ Modelo Supervisado", "üîç Clustering", "üìà Comparaci√≥n de Modelos"],
    label_visibility="collapsed"
)

# Funci√≥n para cargar datos
@st.cache_data
def cargar_datos():
    try:
        df = pd.read_csv('data/academic_performance_master.csv')
        return df
    except FileNotFoundError:
        st.error("‚ùå No se encontr√≥ el archivo 'academic_performance_master.csv' en la carpeta 'data/'")
        st.info("üìÅ Por favor, aseg√∫rate de que el archivo est√© en: `data/academic_performance_master.csv`")
        return None

# Cargar datos
df = cargar_datos()

if df is not None:
    
    # ============= SECCI√ìN: INICIO =============
    if opcion == "üè† Inicio":
        st.header("Bienvenido al Sistema de An√°lisis Acad√©mico")
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("üìä Total de Estudiantes", len(df))
        with col2:
            st.metric("üìã Variables Analizadas", len(df.columns))
        with col3:
            if 'Nota_final' in df.columns:
                promedio = df['Nota_final'].mean()
                st.metric("üìà Promedio General", f"{promedio:.2f}")
        
        st.markdown("""
        ### üìã Objetivo de la Pr√°ctica
        
        Desarrollar modelos de Machine Learning para:
        
        1. **üéØ Modelo Supervisado (Clasificaci√≥n)**
           - Predecir si un estudiante aprobar√° o reprobar√°
           - Utilizar Regresi√≥n Log√≠stica
           - Evaluar con accuracy, matriz de confusi√≥n y m√©tricas
        
        2. **üîç Modelo No Supervisado (Clustering)**
           - Agrupar estudiantes seg√∫n patrones de rendimiento
           - Aplicar K-means con 2-4 clusters
           - Identificar perfiles de estudiantes
        
        ### üéØ Actividades Desarrolladas
        
        ‚úÖ **Carga y exploraci√≥n de datos**
        - Estructura, tipos de datos, estad√≠sticas
        - Identificaci√≥n de problemas de calidad
        
        ‚úÖ **Preparaci√≥n del dataset**
        - Limpieza y estandarizaci√≥n
        - Creaci√≥n de variable objetivo (Aprobado/Reprobado)
        - Codificaci√≥n de variables categ√≥ricas
        - Normalizaci√≥n de datos
        
        ‚úÖ **Modelo Supervisado**
        - Entrenamiento con par√°metros ajustables
        - Accuracy, matriz de confusi√≥n, reporte
        - Interpretaci√≥n de resultados
        
        ‚úÖ **Modelo No Supervisado**
        - K-means con 2-4 clusters
        - Visualizaci√≥n de clusters y centroides
        - An√°lisis de perfiles de estudiantes
        
        ### üß≠ Navegaci√≥n R√°pida
        
        Usa el men√∫ lateral para explorar cada secci√≥n.
        """)
        
        st.info("üí° **Sugerencia:** Comienza por 'Exploraci√≥n de Datos' para entender el dataset.")
    
    # ============= SECCI√ìN: EXPLORACI√ìN =============
    elif opcion == "üìÇ Exploraci√≥n de Datos":
        st.header("1Ô∏è‚É£ Carga y Exploraci√≥n de Datos")
        
        tab1, tab2, tab3, tab4 = st.tabs(["üìä Vista General", "üìà Estad√≠sticas", "üîç Calidad de Datos", "üìâ Visualizaciones"])
        
        with tab1:
            st.subheader("Vista previa del dataset")
            st.dataframe(df.head(20), use_container_width=True)
            
            st.subheader("Informaci√≥n del Dataset")
            col1, col2 = st.columns(2)
            with col1:
                st.write("**üìè Dimensiones:**")
                st.write(f"- Filas: {df.shape[0]}")
                st.write(f"- Columnas: {df.shape[1]}")
            with col2:
                st.write("**üìã Tipos de datos:**")
                tipos = df.dtypes.value_counts()
                for tipo, count in tipos.items():
                    st.write(f"- {tipo}: {count} columnas")
        
        with tab2:
            st.subheader("Estad√≠sticas Descriptivas")
            st.dataframe(df.describe(), use_container_width=True)
            
            if 'Nota_final' in df.columns:
                st.subheader("An√°lisis de la Nota Final")
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("üìâ M√≠nimo", f"{df['Nota_final'].min():.2f}")
                with col2:
                    st.metric("üìä Promedio", f"{df['Nota_final'].mean():.2f}")
                with col3:
                    st.metric("üìç Mediana", f"{df['Nota_final'].median():.2f}")
                with col4:
                    st.metric("üìà M√°ximo", f"{df['Nota_final'].max():.2f}")
        
        with tab3:
            st.subheader("An√°lisis de Calidad de Datos")
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.write("**üîç Valores Nulos:**")
                nulos = df.isnull().sum()
                if nulos.sum() > 0:
                    st.warning(f"‚ö†Ô∏è Se encontraron {nulos.sum()} valores nulos en total")
                    nulos_df = pd.DataFrame({'Columna': nulos[nulos > 0].index, 
                                            'Nulos': nulos[nulos > 0].values})
                    st.dataframe(nulos_df, use_container_width=True)
                else:
                    st.success("‚úÖ No se encontraron valores nulos")
            
            with col2:
                st.write("**üîç Valores Duplicados:**")
                duplicados = df.duplicated().sum()
                if duplicados > 0:
                    st.warning(f"‚ö†Ô∏è Se encontraron {duplicados} filas duplicadas")
                else:
                    st.success("‚úÖ No se encontraron filas duplicadas")
            
            st.write("**üìã Resumen de Tipos:**")
            tipos_info = []
            for col in df.columns:
                tipos_info.append({
                    'Columna': col,
                    'Tipo': str(df[col].dtype),
                    'Valores √∫nicos': df[col].nunique(),
                    'Nulos': df[col].isnull().sum()
                })
            st.dataframe(pd.DataFrame(tipos_info), use_container_width=True)
        
        with tab4:
            st.subheader("Distribuciones de Variables Clave")
            
            if 'Nota_final' in df.columns:
                fig, ax = plt.subplots(1, 2, figsize=(14, 5))
                
                # Histograma
                ax[0].hist(df['Nota_final'].dropna(), bins=25, color='skyblue', edgecolor='black', alpha=0.7)
                ax[0].axvline(df['Nota_final'].mean(), color='red', linestyle='--', linewidth=2, label='Media')
                ax[0].axvline(df['Nota_final'].median(), color='green', linestyle='--', linewidth=2, label='Mediana')
                ax[0].set_title('Distribuci√≥n de Notas Finales', fontsize=14, fontweight='bold')
                ax[0].set_xlabel('Nota Final')
                ax[0].set_ylabel('Frecuencia')
                ax[0].legend()
                ax[0].grid(alpha=0.3)
                
                # Boxplot
                ax[1].boxplot(df['Nota_final'].dropna())
                ax[1].set_title('Boxplot de Notas Finales', fontsize=14, fontweight='bold')
                ax[1].set_ylabel('Nota Final')
                ax[1].grid(alpha=0.3)
                
                st.pyplot(fig)
                plt.close()
            
            # Distribuci√≥n de aprobados vs reprobados
            if 'Nota_final' in df.columns:
                umbral = st.slider("Ajustar umbral de aprobaci√≥n:", 10.0, 16.0, 14.0, 0.5)
                
                aprobado = (df['Nota_final'] >= umbral).sum()
                reprobado = (df['Nota_final'] < umbral).sum()
                
                col1, col2 = st.columns([2, 1])
                
                with col1:
                    fig, ax = plt.subplots(figsize=(8, 6))
                    colors = ['#4CAF50', '#F44336']
                    ax.pie([aprobado, reprobado], labels=['Aprobado', 'Reprobado'], 
                           autopct='%1.1f%%', colors=colors, startangle=90,
                           textprops={'fontsize': 12, 'weight': 'bold'})
                    ax.set_title(f'Distribuci√≥n con umbral = {umbral}', fontsize=14, fontweight='bold')
                    st.pyplot(fig)
                    plt.close()
                
                with col2:
                    st.metric("‚úÖ Aprobados", aprobado, f"{aprobado/len(df)*100:.1f}%")
                    st.metric("‚ùå Reprobados", reprobado, f"{reprobado/len(df)*100:.1f}%")
    
    # ============= SECCI√ìN: PREPARACI√ìN =============
    elif opcion == "üßπ Preparaci√≥n de Datos":
        st.header("2Ô∏è‚É£ Preparaci√≥n del Dataset")
        
        st.subheader("Limpieza y Estandarizaci√≥n")
        
        # Mostrar columnas originales
        st.write("**Columnas disponibles:**")
        st.write(list(df.columns))
        
        # Selecci√≥n de columnas
        st.subheader("Selecci√≥n de Variables")
        
        columnas_disponibles = df.columns.tolist()
        
        col1, col2 = st.columns(2)
        
        with col1:
            nota_col = st.selectbox("Selecciona la columna de Nota Final:", 
                                   ['Nota_final'] if 'Nota_final' in columnas_disponibles else columnas_disponibles)
        
        with col2:
            # Calcular un umbral sugerido basado en la mediana
            if nota_col in df.columns:
                notas_limpias = df[nota_col].dropna()
                min_nota = float(notas_limpias.min())
                max_nota = float(notas_limpias.max())
                mediana_notas = float(notas_limpias.median())
                percentil_40 = float(notas_limpias.quantile(0.4))
                
                # Usar percentil 40 como umbral sugerido (40% reprueba, 60% aprueba)
                umbral_sugerido = round(percentil_40, 1)
                
                st.info(f"üìä Rango de notas: {min_nota:.1f} - {max_nota:.1f} | Mediana: {mediana_notas:.1f}")
            else:
                min_nota, max_nota = 0.0, 20.0
                umbral_sugerido = 14.0
            
            umbral_aprobacion = st.slider("Umbral de aprobaci√≥n (Nota ‚â• umbral):", 
                                         min_nota, max_nota, umbral_sugerido, 0.1)
            
            # Mostrar vista previa de la distribuci√≥n
            if nota_col in df.columns:
                preview_aprobados = (df[nota_col] >= umbral_aprobacion).sum()
                preview_reprobados = (df[nota_col] < umbral_aprobacion).sum()
                preview_total = len(df[nota_col].dropna())
                
                if preview_aprobados > 0 and preview_reprobados > 0:
                    st.success(f"‚úÖ {preview_aprobados} aprobados ({preview_aprobados/preview_total*100:.1f}%) | {preview_reprobados} reprobados ({preview_reprobados/preview_total*100:.1f}%)")
                else:
                    st.error(f"‚ö†Ô∏è {preview_aprobados} aprobados | {preview_reprobados} reprobados - AJUSTA EL UMBRAL")
        
        # Variables predictoras
        st.subheader("Variables Predictoras")
        vars_numericas = df.select_dtypes(include=[np.number]).columns.tolist()
        if nota_col in vars_numericas:
            vars_numericas.remove(nota_col)
        
        # Filtrar variables in√∫tiles
        vars_numericas = [v for v in vars_numericas if v not in ['Identificacion_Estudiante', 'Cedula_docente']]
        
        if len(vars_numericas) == 0:
            st.warning("‚ö†Ô∏è No hay variables num√©ricas para predecir. Usa variables categ√≥ricas.")
            variables_x = []
        else:
            variables_x = st.multiselect(
                "Selecciona las variables num√©ricas para predecir (X):",
                vars_numericas,
                default=['Asistencia'] if 'Asistencia' in vars_numericas else (vars_numericas[:1] if vars_numericas else [])
            )
        
        # An√°lisis de distribuci√≥n antes de preparar
        if nota_col in df.columns:
            st.subheader("üìä An√°lisis de Distribuci√≥n de Notas")
            
            col1, col2 = st.columns(2)
            
            with col1:
                fig, ax = plt.subplots(figsize=(8, 5))
                ax.hist(df[nota_col].dropna(), bins=20, color='skyblue', edgecolor='black', alpha=0.7)
                ax.axvline(umbral_aprobacion, color='red', linestyle='--', linewidth=2, label=f'Umbral = {umbral_aprobacion}')
                ax.axvline(df[nota_col].median(), color='green', linestyle='--', linewidth=2, label=f'Mediana = {df[nota_col].median():.1f}')
                ax.set_title('Distribuci√≥n de Notas', fontsize=12, fontweight='bold')
                ax.set_xlabel('Nota Final')
                ax.set_ylabel('Frecuencia')
                ax.legend()
                ax.grid(alpha=0.3)
                st.pyplot(fig)
                plt.close()
            
            with col2:
                aprobados_preview = (df[nota_col] >= umbral_aprobacion).sum()
                reprobados_preview = (df[nota_col] < umbral_aprobacion).sum()
                total_preview = len(df[nota_col].dropna())
                
                st.metric("Total de registros", total_preview)
                st.metric("‚úÖ Aprobados", aprobados_preview, f"{aprobados_preview/total_preview*100:.1f}%")
                st.metric("‚ùå Reprobados", reprobados_preview, f"{reprobados_preview/total_preview*100:.1f}%")
                
                # Advertencia si solo hay una clase
                if aprobados_preview == 0 or reprobados_preview == 0:
                    st.error("‚ö†Ô∏è ADVERTENCIA: Solo hay una clase con este umbral!")
                    st.info(f"üí° Sugerencia: Ajusta el umbral entre {df[nota_col].min():.1f} y {df[nota_col].max():.1f}")
                elif min(aprobados_preview, reprobados_preview) / max(aprobados_preview, reprobados_preview) < 0.1:
                    st.warning("‚ö†Ô∏è Clases muy desbalanceadas. Considera ajustar el umbral.")
                else:
                    st.success("‚úÖ Distribuci√≥n aceptable")
        
        # Variables categ√≥ricas
        st.subheader("Codificaci√≥n de Variables Categ√≥ricas")
        vars_categoricas = df.select_dtypes(include=['object']).columns.tolist()
        
        vars_cat_selec = []
        if len(vars_categoricas) > 0:
            st.write(f"**Variables categ√≥ricas detectadas:** {vars_categoricas}")
            codificar_cats = st.checkbox("Incluir variables categ√≥ricas", value=False)
            
            if codificar_cats:
                vars_cat_selec = st.multiselect("Selecciona variables categ√≥ricas:", vars_categoricas)
        
        if st.button("üîß Preparar Dataset", type="primary"):
            if len(variables_x) == 0 and len(vars_cat_selec) == 0:
                st.error("‚ùå Debes seleccionar al menos una variable predictora")
            else:
                # Crear dataset limpio
                columnas_usar = [nota_col] + variables_x + vars_cat_selec
                df_prep = df[columnas_usar].copy()
                
                # Limpiar nulos
                nulos_antes = df_prep.isnull().sum().sum()
                df_prep = df_prep.dropna()
                
                if len(df_prep) == 0:
                    st.error("‚ùå No quedan datos despu√©s de eliminar nulos")
                    st.stop()
                
                st.success(f"‚úÖ Limpieza completada: Eliminados {nulos_antes} valores nulos, quedan {len(df_prep)} registros")
                
                # Codificar categ√≥ricas
                if len(vars_cat_selec) > 0:
                    le = LabelEncoder()
                    for col in vars_cat_selec:
                        if col in df_prep.columns:
                            df_prep[col] = le.fit_transform(df_prep[col].astype(str))
                    st.success(f"‚úÖ Variables categ√≥ricas codificadas: {vars_cat_selec}")
                
                # Crear variable objetivo
                df_prep['Aprobado'] = (df_prep[nota_col] >= umbral_aprobacion).astype(int)
                
                # Verificar distribuci√≥n
                distribucion = df_prep['Aprobado'].value_counts()
                
                col1, col2, col3 = st.columns(3)
                with col1:
                    aprobados = distribucion.get(1, 0)
                    st.metric("‚úÖ Aprobados (1)", aprobados, f"{aprobados/len(df_prep)*100:.1f}%")
                with col2:
                    reprobados = distribucion.get(0, 0)
                    st.metric("‚ùå Reprobados (0)", reprobados, f"{reprobados/len(df_prep)*100:.1f}%")
                with col3:
                    if len(distribucion) >= 2:
                        balance = min(aprobados, reprobados) / max(aprobados, reprobados)
                        st.metric("‚öñÔ∏è Balance", f"{balance:.2%}")
                
                # Variables finales
                variables_finales = [v for v in variables_x + vars_cat_selec if v in df_prep.columns and v != nota_col]
                
                # Guardar en session state
                st.session_state['df_preparado'] = df_prep
                st.session_state['nota_col'] = nota_col
                st.session_state['variables_x'] = variables_finales
                st.session_state['umbral'] = umbral_aprobacion
                
                if len(distribucion) < 2:
                    st.error("‚ùå El dataset solo tiene una clase. Ajusta el umbral de aprobaci√≥n.")
                elif len(variables_finales) == 0:
                    st.error("‚ùå No hay variables predictoras v√°lidas")
                else:
                    st.success("‚úÖ Dataset preparado correctamente. Puedes continuar al modelo supervisado.")
                    
                    # Mostrar preview
                    st.subheader("Vista Previa del Dataset Preparado")
                    st.dataframe(df_prep.head(10), use_container_width=True)
    
    # ============= SECCI√ìN: MODELO SUPERVISADO =============
    elif opcion == "ü§ñ Modelo Supervisado":
        st.header("3Ô∏è‚É£ Modelo de Clasificaci√≥n Supervisado")
        
        if 'df_preparado' not in st.session_state:
            st.warning("‚ö†Ô∏è Primero debes preparar el dataset en la secci√≥n 'Preparaci√≥n de Datos'")
            st.stop()
        
        df_modelo = st.session_state['df_preparado']
        variables_x = st.session_state['variables_x']
        
        if len(variables_x) == 0:
            st.error("‚ùå No hay variables predictoras. Regresa a 'Preparaci√≥n de Datos'")
            st.stop()
        
        st.subheader("Configuraci√≥n del Modelo")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            algoritmo = st.selectbox("Algoritmo:", 
                                    ["Regresi√≥n Log√≠stica", "√Årbol de Decisi√≥n", "Random Forest"])
        
        with col2:
            test_size = st.slider("% Datos de prueba:", 10, 40, 20) / 100
        
        with col3:
            random_state = st.number_input("Semilla aleatoria:", 0, 100, 42)
        
        if st.button("üöÄ Entrenar Modelo", type="primary"):
            # Preparar datos
            X = df_modelo[variables_x]
            y = df_modelo['Aprobado']
            
            # Verificar clases
            if len(y.unique()) < 2:
                st.error("‚ùå Solo hay una clase en los datos. Ajusta el umbral de aprobaci√≥n.")
                st.stop()
            
            try:
                # Divisi√≥n
                X_train, X_test, y_train, y_test = train_test_split(
                    X, y, test_size=test_size, random_state=random_state, stratify=y
                )
                
                # Escalado
                scaler = StandardScaler()
                X_train_scaled = scaler.fit_transform(X_train)
                X_test_scaled = scaler.transform(X_test)
                
                # Seleccionar modelo
                if algoritmo == "Regresi√≥n Log√≠stica":
                    modelo = LogisticRegression(random_state=random_state, max_iter=1000)
                elif algoritmo == "√Årbol de Decisi√≥n":
                    modelo = DecisionTreeClassifier(random_state=random_state)
                else:
                    modelo = RandomForestClassifier(random_state=random_state, n_estimators=100)
                
                # Entrenar
                with st.spinner('Entrenando modelo...'):
                    modelo.fit(X_train_scaled, y_train)
                
                # Predicciones
                y_pred = modelo.predict(X_test_scaled)
                
                # M√©tricas
                st.success("‚úÖ Modelo entrenado exitosamente")
                
                st.subheader("üìä Resultados del Entrenamiento")
                
                accuracy = accuracy_score(y_test, y_pred)
                
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("üéØ Accuracy", f"{accuracy:.2%}")
                with col2:
                    st.metric("üìä Muestras entrenamiento", len(X_train))
                with col3:
                    st.metric("üìä Muestras prueba", len(X_test))
                
                # Interpretaci√≥n del accuracy
                if accuracy >= 0.90:
                    st.success("üåü Excelente desempe√±o del modelo")
                elif accuracy >= 0.80:
                    st.info("‚úÖ Buen desempe√±o del modelo")
                elif accuracy >= 0.70:
                    st.warning("‚ö†Ô∏è Desempe√±o aceptable, podr√≠a mejorar")
                else:
                    st.error("‚ùå Desempe√±o bajo, considera ajustar el modelo")
                
                # Matriz de confusi√≥n
                st.subheader("üìà Matriz de Confusi√≥n")
                cm = confusion_matrix(y_test, y_pred)
                
                fig, ax = plt.subplots(figsize=(8, 6))
                sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                           xticklabels=['Reprobado (0)', 'Aprobado (1)'],
                           yticklabels=['Reprobado (0)', 'Aprobado (1)'],
                           cbar_kws={'label': 'Frecuencia'},
                           annot_kws={'size': 16, 'weight': 'bold'})
                ax.set_title(f'Matriz de Confusi√≥n - {algoritmo}', fontsize=14, fontweight='bold')
                ax.set_ylabel('Valor Real', fontsize=12)
                ax.set_xlabel('Predicci√≥n', fontsize=12)
                plt.tight_layout()
                st.pyplot(fig)
                plt.close()
                
                # Explicaci√≥n de la matriz
                with st.expander("‚ÑπÔ∏è ¬øC√≥mo interpretar la matriz de confusi√≥n?"):
                    st.markdown(f"""
                    - **Verdaderos Negativos (TN):** {cm[0,0]} - Reprobados correctamente predichos
                    - **Falsos Positivos (FP):** {cm[0,1]} - Reprobados predichos como aprobados (Error Tipo I)
                    - **Falsos Negativos (FN):** {cm[1,0]} - Aprobados predichos como reprobados (Error Tipo II)
                    - **Verdaderos Positivos (TP):** {cm[1,1]} - Aprobados correctamente predichos
                    """)
                
                # Reporte de clasificaci√≥n
                st.subheader("üìã Reporte de Clasificaci√≥n Detallado")
                report = classification_report(y_test, y_pred, 
                                              target_names=['Reprobado', 'Aprobado'],
                                              output_dict=True)
                report_df = pd.DataFrame(report).transpose()
                st.dataframe(report_df.style.highlight_max(axis=0, color='lightgreen'), 
                           use_container_width=True)
                
                with st.expander("‚ÑπÔ∏è Explicaci√≥n de m√©tricas"):
                    st.markdown("""
                    - **Precision:** De todos los que el modelo predijo como aprobados, ¬øcu√°ntos realmente lo son?
                    - **Recall:** De todos los que realmente aprobaron, ¬øcu√°ntos el modelo identific√≥ correctamente?
                    - **F1-Score:** Media arm√≥nica entre Precision y Recall
                    - **Support:** N√∫mero de muestras de cada clase
                    """)
                
                # Importancia de caracter√≠sticas
                st.subheader("üìä Importancia de Variables")
                
                if algoritmo == "Regresi√≥n Log√≠stica":
                    importancias = pd.DataFrame({
                        'Variable': variables_x,
                        'Coeficiente': modelo.coef_[0],
                        'Importancia_Abs': np.abs(modelo.coef_[0])
                    }).sort_values('Importancia_Abs', ascending=False)
                    
                    fig, ax = plt.subplots(figsize=(10, 6))
                    colors = ['green' if x > 0 else 'red' for x in importancias['Coeficiente']]
                    ax.barh(importancias['Variable'], importancias['Coeficiente'], color=colors, alpha=0.7)
                    ax.set_xlabel('Coeficiente', fontsize=12)
                    ax.set_title('Importancia de Variables\n(Verde: Influencia Positiva | Rojo: Influencia Negativa)', 
                                fontsize=14, fontweight='bold')
                    ax.axvline(x=0, color='black', linestyle='--', linewidth=1)
                    ax.grid(axis='x', alpha=0.3)
                    plt.tight_layout()
                    st.pyplot(fig)
                    plt.close()
                    
                    st.write("**Interpretaci√≥n:**")
                    st.dataframe(importancias[['Variable', 'Coeficiente']], use_container_width=True)
                
                # Guardar resultados
                st.session_state['modelo_supervisado'] = {
                    'accuracy': accuracy,
                    'modelo': algoritmo,
                    'tipo': 'Supervisado - Clasificaci√≥n',
                    'cm': cm,
                    'report': report
                }
                
                st.success("‚úÖ Resultados guardados. Puedes continuar al clustering o comparar modelos.")
                
            except Exception as e:
                st.error(f"‚ùå Error al entrenar el modelo: {str(e)}")
                st.info("üí° Verifica que tengas suficientes datos de ambas clases.")
    
    # ============= SECCI√ìN: CLUSTERING =============
    elif opcion == "üîç Clustering":
        st.header("4Ô∏è‚É£ An√°lisis de Clustering (K-means)")
        
        st.subheader("Configuraci√≥n del Clustering")
        
        # Selecci√≥n de variables
        vars_numericas = df.select_dtypes(include=[np.number]).columns.tolist()
        
        if len(vars_numericas) < 2:
            st.error("‚ùå Se necesitan al menos 2 variables num√©ricas para clustering")
            st.stop()
        
        col1, col2 = st.columns(2)
        with col1:
            var_x = st.selectbox("Variable X (horizontal):", vars_numericas, index=0)
        with col2:
            var_y_options = [v for v in vars_numericas if v != var_x]
            var_y = st.selectbox("Variable Y (vertical):", var_y_options, 
                                index=0 if var_y_options else 0)
        
        n_clusters = st.slider("N√∫mero de clusters (k):", 2, 6, 3)
        
        if st.button("üîç Realizar Clustering", type="primary"):
            # Preparar datos
            df_cluster = df[[var_x, var_y]].dropna()
            
            if len(df_cluster) < n_clusters:
                st.error(f"‚ùå No hay suficientes datos. Se necesitan al menos {n_clusters} registros.")
                st.stop()
            
            # Escalado
            scaler = StandardScaler()
            X_scaled = scaler.fit_transform(df_cluster)
            
            # K-means
            with st.spinner('Aplicando K-means...'):
                kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
                clusters = kmeans.fit_predict(X_scaled)
            
            df_cluster['Cluster'] = clusters
            
            st.success(f"‚úÖ Clustering completado con {n_clusters} clusters")
            
            # Visualizaci√≥n principal
            st.subheader("üìä Visualizaci√≥n de Clusters")
            
            fig, ax = plt.subplots(figsize=(12, 8))
            
            scatter = ax.scatter(df_cluster[var_x], df_cluster[var_y], 
                               c=clusters, cmap='viridis', alpha=0.6, s=100, 
                               edgecolors='black', linewidth=0.5)
            
            # Centroides
            centroides = scaler.inverse_transform(kmeans.cluster_centers_)
            ax.scatter(centroides[:, 0], centroides[:, 1], 
                      c='red', marker='X', s=500, edgecolors='black',
                      linewidths=3, label='Centroides', zorder=5)
            
            # Etiquetar centroides
            for i, (x, y) in enumerate(centroides):
                ax.annotate(f'C{i}', (x, y), fontsize=14, fontweight='bold', 
                           color='white', ha='center', va='center')
            
            ax.set_xlabel(var_x, fontsize=12, fontweight='bold')
            ax.set_ylabel(var_y, fontsize=12, fontweight='bold')
            ax.set_title(f'Clustering K-means (k={n_clusters})', fontsize=14, fontweight='bold')
            ax.legend(fontsize=11)
            ax.grid(True, alpha=0.3)
            
            cbar = plt.colorbar(scatter, ax=ax)
            cbar.set_label('Cluster', fontsize=11, fontweight='bold')
            
            plt.tight_layout()
            st.pyplot(fig)
            plt.close()
            
            # An√°lisis por cluster
            st.subheader("üìã An√°lisis de Cada Cluster")
            
            for i in range(n_clusters):
                with st.expander(f"üìä Cluster {i} - {len(df_cluster[df_cluster['Cluster']==i])} estudiantes"):
                    cluster_data = df_cluster[df_cluster['Cluster']==i]
                    
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.metric(f"Promedio {var_x}", f"{cluster_data[var_x].mean():.2f}")
                        st.metric(f"Desv. Est. {var_x}", f"{cluster_data[var_x].std():.2f}")
                    
                    with col2:
                        st.metric(f"Promedio {var_y}", f"{cluster_data[var_y].mean():.2f}")
                        st.metric(f"Desv. Est. {var_y}", f"{cluster_data[var_y].std():.2f}")
                    
                    st.write("**Interpretaci√≥n:**")
                    if cluster_data[var_y].mean() > df_cluster[var_y].mean():
                        if cluster_data[var_x].mean() > df_cluster[var_x].mean():
                            st.success("‚úÖ Grupo de alto rendimiento con buena asistencia")
                        else:
                            st.info("üìä Grupo de buen rendimiento pero asistencia mejorable")
                    else:
                        if cluster_data[var_x].mean() < df_cluster[var_x].mean():
                            st.error("‚ö†Ô∏è Grupo de bajo rendimiento y baja asistencia (Requiere atenci√≥n)")
                        else:
                            st.warning("üìâ Grupo con asistencia aceptable pero bajo rendimiento")
            
            # Resumen estad√≠stico
            st.subheader("üìä Resumen Estad√≠stico por Cluster")
            resumen = df_cluster.groupby('Cluster')[[var_x, var_y]].agg(['mean', 'std', 'min', 'max'])
            st.dataframe(resumen.style.highlight_max(axis=0, color='lightgreen').highlight_min(axis=0, color='lightcoral'), 
                        use_container_width=True)
            
            # Guardar resultados
            st.session_state['clustering'] = {
                'n_clusters': n_clusters,
                'var_x': var_x,
                'var_y': var_y,
                'tipo': 'No Supervisado - Clustering',
                'centroides': centroides
            }
            
            st.success("‚úÖ An√°lisis de clustering completado. Puedes ir a 'Comparaci√≥n de Modelos'.")
    
    # ============= SECCI√ìN: COMPARACI√ìN =============
    elif opcion == "üìà Comparaci√≥n de Modelos":
        st.header("5Ô∏è‚É£ Comparaci√≥n de Modelos")
        
        if 'modelo_supervisado' not in st.session_state and 'clustering' not in st.session_state:
            st.warning("‚ö†Ô∏è Debes ejecutar al menos un modelo para ver la comparaci√≥n")
            st.stop()
        
        st.subheader("üîç Resumen de Modelos Implementados")
        
        # Modelo Supervisado
        if 'modelo_supervisado' in st.session_state:
            st.markdown("### ü§ñ Modelo Supervisado (Clasificaci√≥n)")
            
            modelo_sup = st.session_state['modelo_supervisado']
            
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("Tipo de Modelo", modelo_sup['modelo'])
            with col2:
                st.metric("Accuracy", f"{modelo_sup['accuracy']:.2%}")
            with col3:
                st.metric("Tipo de Aprendizaje", modelo_sup['tipo'])
            
            st.markdown("**üéØ Objetivo:** Predecir si un estudiante aprobar√° o reprobar√°")
            st.markdown(f"**üìä Desempe√±o:** {'Excelente' if modelo_sup['accuracy'] >= 0.9 else 'Bueno' if modelo_sup['accuracy'] >= 0.8 else 'Aceptable'}")
            
            # M√©tricas detalladas
            with st.expander("üìã Ver m√©tricas detalladas"):
                report_df = pd.DataFrame(modelo_sup['report']).transpose()
                st.dataframe(report_df, use_container_width=True)
            
            st.markdown("---")
        
        # Modelo No Supervisado
        if 'clustering' in st.session_state:
            st.markdown("### üîç Modelo No Supervisado (Clustering)")
            
            clustering = st.session_state['clustering']
            
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("Algoritmo", "K-means")
            with col2:
                st.metric("N√∫mero de Clusters", clustering['n_clusters'])
            with col3:
                st.metric("Tipo de Aprendizaje", clustering['tipo'])
            
            st.markdown("**üéØ Objetivo:** Agrupar estudiantes seg√∫n patrones de rendimiento")
            st.markdown(f"**üìä Variables:** {clustering['var_x']} vs {clustering['var_y']}")
            
            st.markdown("---")
        
        # Comparaci√≥n
        st.subheader("‚öñÔ∏è Comparaci√≥n y Conclusiones")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("#### ü§ñ Modelo Supervisado")
            st.markdown("""
            **Ventajas:**
            - ‚úÖ Predice resultados espec√≠ficos (Aprobado/Reprobado)
            - ‚úÖ Permite medir accuracy y m√©tricas
            - ‚úÖ √ötil para predicciones futuras
            
            **Limitaciones:**
            - ‚ùå Requiere datos etiquetados
            - ‚ùå Depende de la calidad del umbral definido
            """)
        
        with col2:
            st.markdown("#### üîç Modelo No Supervisado")
            st.markdown("""
            **Ventajas:**
            - ‚úÖ Descubre patrones ocultos
            - ‚úÖ No requiere etiquetas previas
            - ‚úÖ Identifica grupos naturales
            
            **Limitaciones:**
            - ‚ùå No predice valores espec√≠ficos
            - ‚ùå Interpretaci√≥n m√°s subjetiva
            """)
        
        st.markdown("---")
        
        # Recomendaciones
        st.subheader("üí° Recomendaciones y Conclusiones")
        
        st.markdown("""
        ### üéØ ¬øCu√°l modelo es mejor?
        
        **No hay un modelo "mejor" en t√©rminos absolutos**, sino que cada uno sirve para prop√≥sitos diferentes:
        
        1. **Usa el Modelo Supervisado cuando:**
           - Necesitas predecir si un estudiante aprobar√° o no
           - Quieres evaluar el impacto de variables espec√≠ficas
           - Tienes datos hist√≥ricos con resultados conocidos
        
        2. **Usa el Modelo No Supervisado cuando:**
           - Quieres descubrir grupos naturales de estudiantes
           - Buscas identificar perfiles o patrones no obvios
           - Necesitas segmentar estudiantes para intervenciones personalizadas
        
        ### üîÑ Uso Combinado (Recomendado)
        
        La mejor estrategia es usar **ambos modelos de forma complementaria**:
        
        1. **Clustering** para identificar grupos de riesgo o perfiles
        2. **Clasificaci√≥n** para predecir resultados individuales
        3. **Intervenciones personalizadas** seg√∫n el cluster y la predicci√≥n
        
        ### üìä Aplicaci√≥n Pr√°ctica
        
        **Ejemplo de uso:**
        - El clustering identifica un grupo de "estudiantes en riesgo" (baja asistencia + notas bajas)
        - El modelo supervisado predice qu√© estudiantes espec√≠ficos reprobar√°n
        - La instituci√≥n puede implementar tutor√≠as focalizadas en ese grupo
        
        ### ‚úÖ Resultados Obtenidos en esta Pr√°ctica
        """)
        
        if 'modelo_supervisado' in st.session_state:
            accuracy = st.session_state['modelo_supervisado']['accuracy']
            st.success(f"‚úÖ Modelo Supervisado: {accuracy:.1%} de accuracy - {'Excelente' if accuracy >= 0.9 else 'Bueno' if accuracy >= 0.8 else 'Aceptable'} desempe√±o")
        
        if 'clustering' in st.session_state:
            n_clusters = st.session_state['clustering']['n_clusters']
            st.info(f"‚úÖ Clustering: {n_clusters} grupos identificados con patrones diferenciados")
        
        st.markdown("""
        ### üéì Conclusi√≥n Final
        
        Los modelos de Machine Learning son herramientas complementarias que, cuando se usan en conjunto, 
        proporcionan una visi√≥n m√°s completa del rendimiento acad√©mico y permiten implementar estrategias 
        de intervenci√≥n m√°s efectivas y personalizadas.
        """)

else:
    st.error("‚ùå No se pudo cargar el dataset. Verifica que el archivo exista en la carpeta 'data/'")
    st.stop()